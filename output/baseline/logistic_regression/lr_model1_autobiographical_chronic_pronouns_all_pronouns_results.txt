MODEL USED FOR PREDICTIONS: logistic_regression
2023-04-02 11:12:16.284806
optimizer: adam
lr: 0.2
batch_size: 200
epochs: 100
train_loss: 0.47037094831466675
val_loss: 0.9068179130554199
test_loss: [0.9152069687843323, 0.5]



CLASSIFICATION REPORT: 
              precision    recall  f1-score   support

           0       0.50      1.00      0.67         6
           1       0.00      0.00      0.00         6

    accuracy                           0.50        12
   macro avg       0.25      0.50      0.33        12
weighted avg       0.25      0.50      0.33        12
MODEL USED FOR PREDICTIONS: logistic_regression

2023-04-05 16:56:29.647813

optimizer: adam
lr: 0.001
batch_size: 8
epochs: 10
train_loss: 0.7449367642402649
val_loss: 0.6878402829170227
test_loss: 0.684454619884491


CLASSIFICATION REPORT: 
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         6
           1       0.50      1.00      0.67         6

    accuracy                           0.50        12
   macro avg       0.25      0.50      0.33        12
weighted avg       0.25      0.50      0.33        12
MODEL USED FOR PREDICTIONS: logistic_regression

2023-04-10 15:10:35.426702

optimizer: adam
lr: 0.001
batch_size: 16
epochs: 10
train_loss: 0.7799970507621765
val_loss: 0.6894541382789612
test_loss: 0.706202507019043

weights: [[array([[0.62464464]], dtype=float32), array([-0.02935718], dtype=float32)]]


CLASSIFICATION REPORT: 
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         6
           1       0.50      1.00      0.67         6

    accuracy                           0.50        12
   macro avg       0.25      0.50      0.33        12
weighted avg       0.25      0.50      0.33        12
MODEL USED FOR PREDICTIONS: logistic_regression

2023-04-17 10:13:54.203152

optimizer: sgd
lr: 0.001
batch_size: 8
epochs: 100
train_loss: 0.6000431776046753
val_loss: 0.7190543413162231
test_loss: 0.7222143411636353

weights: [[array([[-0.66854894]], dtype=float32), array([-0.12358966], dtype=float32)]]


CLASSIFICATION REPORT: 
              precision    recall  f1-score   support

           0       0.50      1.00      0.67         5
           1       0.00      0.00      0.00         5

    accuracy                           0.50        10
   macro avg       0.25      0.50      0.33        10
weighted avg       0.25      0.50      0.33        10
MODEL USED FOR PREDICTIONS: logistic_regression

2023-04-17 17:18:03.131038

optimizer: sgd
lr: 0.01
batch_size: 16
epochs: 100
train_loss: 0.554827094078064
val_loss: 0.8228495717048645
test_loss: 0.8278414607048035

weights: [[array([[-1.4991748]], dtype=float32), array([-0.23294654], dtype=float32)]]


CLASSIFICATION REPORT: 
              precision    recall  f1-score   support

           0       0.50      1.00      0.67         6
           1       0.00      0.00      0.00         6

    accuracy                           0.50        12
   macro avg       0.25      0.50      0.33        12
weighted avg       0.25      0.50      0.33        12
