MODEL USED FOR PREDICTIONS: logistic_regression

2023-04-10 10:51:09.076043

optimizer: adam
lr: 0.1
batch_size: 8
epochs: 100
train_loss: 0.6074745059013367
val_loss: 0.5016664266586304
test_loss: 0.6575677990913391

weights: [[array([[-5.406486]], dtype=float32), array([3.346629], dtype=float32)]]


CLASSIFICATION REPORT: 
              precision    recall  f1-score   support

           0       0.50      0.62      0.56         8
           1       0.50      0.38      0.43         8

    accuracy                           0.50        16
   macro avg       0.50      0.50      0.49        16
weighted avg       0.50      0.50      0.49        16
MODEL USED FOR PREDICTIONS: logistic_regression

2023-04-10 13:39:14.540098

optimizer: adam
lr: 0.1
batch_size: 8
epochs: 100
train_loss: 0.6223412752151489
val_loss: 0.5056528449058533
test_loss: 0.6604868173599243

weights: [[array([[-4.8995147]], dtype=float32), array([2.8219461], dtype=float32)]]


CLASSIFICATION REPORT: 
              precision    recall  f1-score   support

           0       0.55      0.75      0.63         8
           1       0.60      0.38      0.46         8

    accuracy                           0.56        16
   macro avg       0.57      0.56      0.55        16
weighted avg       0.57      0.56      0.55        16
MODEL USED FOR PREDICTIONS: logistic_regression

2023-04-10 15:11:55.699807

optimizer: adam
lr: 0.1
batch_size: 8
epochs: 100
train_loss: 0.5902295708656311
val_loss: 0.5487977266311646
test_loss: 0.6562547087669373

weights: [[array([[-5.6304917]], dtype=float32), array([3.505885], dtype=float32)]]


CLASSIFICATION REPORT: 
              precision    recall  f1-score   support

           0       0.56      0.62      0.59         8
           1       0.57      0.50      0.53         8

    accuracy                           0.56        16
   macro avg       0.56      0.56      0.56        16
weighted avg       0.56      0.56      0.56        16
MODEL USED FOR PREDICTIONS: logistic_regression

2023-04-17 10:14:18.114745

optimizer: adam
lr: 0.1
batch_size: 64
epochs: 100
train_loss: 0.5946314930915833
val_loss: 0.5428215265274048
test_loss: 0.6262403130531311

weights: [[array([[-6.052857]], dtype=float32), array([3.8059623], dtype=float32)]]


CLASSIFICATION REPORT: 
              precision    recall  f1-score   support

           0       0.62      0.83      0.71         6
           1       0.75      0.50      0.60         6

    accuracy                           0.67        12
   macro avg       0.69      0.67      0.66        12
weighted avg       0.69      0.67      0.66        12
MODEL USED FOR PREDICTIONS: logistic_regression

2023-04-17 17:18:56.816673

optimizer: adam
lr: 0.1
batch_size: 8
epochs: 100
train_loss: 0.6253867745399475
val_loss: 0.5204159617424011
test_loss: 0.5468024015426636

weights: [[array([[-4.7898006]], dtype=float32), array([3.08574], dtype=float32)]]


CLASSIFICATION REPORT: 
              precision    recall  f1-score   support

           0       0.75      0.75      0.75         8
           1       0.75      0.75      0.75         8

    accuracy                           0.75        16
   macro avg       0.75      0.75      0.75        16
weighted avg       0.75      0.75      0.75        16
