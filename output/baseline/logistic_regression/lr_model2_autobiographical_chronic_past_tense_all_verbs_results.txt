MODEL USED FOR PREDICTIONS: logistic_regression
2023-04-02 11:12:19.137666
optimizer: adam
lr: 0.01
batch_size: 200
epochs: 100
train_loss: 0.4632705748081207
val_loss: 0.8695123791694641
test_loss: [0.9072670936584473, 0.5]



CLASSIFICATION REPORT: 
              precision    recall  f1-score   support

           0       0.50      1.00      0.67         6
           1       0.00      0.00      0.00         6

    accuracy                           0.50        12
   macro avg       0.25      0.50      0.33        12
weighted avg       0.25      0.50      0.33        12
MODEL USED FOR PREDICTIONS: logistic_regression

2023-04-05 16:56:34.767741

optimizer: adam
lr: 0.001
batch_size: 64
epochs: 10
train_loss: 1.0131927728652954
val_loss: 0.7772667407989502
test_loss: 0.7264006733894348


CLASSIFICATION REPORT: 
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         6
           1       0.50      1.00      0.67         6

    accuracy                           0.50        12
   macro avg       0.25      0.50      0.33        12
weighted avg       0.25      0.50      0.33        12
MODEL USED FOR PREDICTIONS: logistic_regression

2023-04-10 15:10:41.659875

optimizer: adam
lr: 0.001
batch_size: 32
epochs: 10
train_loss: 0.5491957664489746
val_loss: 0.7069797515869141
test_loss: 0.7214210629463196

weights: [[array([[-1.2086189]], dtype=float32), array([-0.01662358], dtype=float32)]]


CLASSIFICATION REPORT: 
              precision    recall  f1-score   support

           0       0.50      1.00      0.67         6
           1       0.00      0.00      0.00         6

    accuracy                           0.50        12
   macro avg       0.25      0.50      0.33        12
weighted avg       0.25      0.50      0.33        12
MODEL USED FOR PREDICTIONS: logistic_regression

2023-04-17 10:13:55.364280

optimizer: adam
lr: 0.001
batch_size: 16
epochs: 10
train_loss: 0.5716944336891174
val_loss: 0.7185642123222351
test_loss: 0.6957681179046631

weights: [[array([[-1.1281606]], dtype=float32), array([-0.02627463], dtype=float32)]]


CLASSIFICATION REPORT: 
              precision    recall  f1-score   support

           0       0.50      1.00      0.67         5
           1       0.00      0.00      0.00         5

    accuracy                           0.50        10
   macro avg       0.25      0.50      0.33        10
weighted avg       0.25      0.50      0.33        10
MODEL USED FOR PREDICTIONS: logistic_regression

2023-04-17 17:18:06.123033

optimizer: sgd
lr: 0.1
batch_size: 64
epochs: 10
train_loss: 0.5404163599014282
val_loss: 0.7829939723014832
test_loss: 0.7434952855110168

weights: [[array([[-1.5548867]], dtype=float32), array([-0.10046803], dtype=float32)]]


CLASSIFICATION REPORT: 
              precision    recall  f1-score   support

           0       0.50      1.00      0.67         6
           1       0.00      0.00      0.00         6

    accuracy                           0.50        12
   macro avg       0.25      0.50      0.33        12
weighted avg       0.25      0.50      0.33        12
